# AI Medical Chatbot
A Retrieval-Augmented Generation (RAG) based chatbot designed to answer medical-related questions by leveraging PDF documents as its knowledge base. Built using LangChain, Hugging Face embeddings, FAISS vector store, and Streamlit for the user interface, this chatbot retrieves relevant information from uploaded PDFs and provides concise, context-based answers.

# Features
PDF Processing: Extracts text from PDF files in a specified directory.
Text Chunking: Splits documents into manageable chunks for efficient retrieval.
Vector Store: Uses FAISS to store embeddings generated by Hugging Face's sentence-transformers/all-MiniLM-L6-v2 model.
LLM Integration: Powered by Hugging Face's Mistral-7B-Instruct-v0.3 model for natural language understanding and generation.
Streamlit UI: Interactive web interface for users to ask questions and receive answers.
Custom Prompting: Ensures answers are strictly based on provided context, avoiding hallucination.
# Prerequisites
Python 3.8+
Hugging Face account and API token (for accessing the LLM)
Required Python libraries (listed in requirements.txt)
Installation
Clone the Repository

## Step 1:
```bash
git clone https://github.com/yourusername/ai-medical-chatbot.git
cd ai-medical-chatbot
```

## Step 2:
Set Up a Virtual Environment (optional but recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

## Step 3:
Install Dependencies

```bash
pip install -r requirements.txt
```

## Step 4:
requirement.txt

```bash
streamlit
langchain
langchain-community
langchain-huggingface
sentence-transformers
faiss-cpu
PyPDF2
```

## Step 5:
Set Environment Variables
Create a .env file in the root directory and add your Hugging Face API token:

HF_TOKEN = huggingface_api_token

## Step 6:
Prepare Data

Place your medical PDF files in the 'data/' directory.
The chatbot will process all .pdf files in this folder.


## Usage:
1. Generate the Vector Store
Run the initial script to process PDFs and create the FAISS vector store:

```bash
python process_pdfs.py
```

This script:

Loads PDFs from the data/ directory.
Splits them into chunks.
Generates embeddings using Hugging Face's all-MiniLM-L6-v2 model.
Saves the vector store to vectorstore/db_faiss.
Note: Replace process_pdfs.py with the actual filename if you save the first part of your code separately.

2. Run the Chatbot
Launch the Streamlit app:

```bash
streamlit run app.py
```

Open your browser to 
```bash
http://localhost:8501.
```

Enter your question in the chat input field and receive answers based on the PDF content.
Project Structure

ai-medical-chatbot/
├── data/                  # Directory for PDF files
├── vectorstore/           # Directory for FAISS vector store
│   └── db_faiss/
├── app.py                # Main Streamlit application
├── process_pdfs.py       # Script to process PDFs and create vector store
├── requirements.txt      # List of dependencies
├── .env                  # Environment variables (e.g., HF_TOKEN)
└── README.md             # This file

## How It Works:

1. PDF Processing: PDFs are loaded and split into chunks of 500 characters with a 50-character overlap.
2. Embedding Generation: Text chunks are converted into 384-dimensional vectors using Hugging Face embeddings.
3. Vector Store: FAISS indexes the embeddings for fast similarity search.
4. Query Handling: User questions are embedded, and the top 3 relevant chunks are retrieved from the vector store.
5. Response Generation: The Mistral-7B model generates answers based on the retrieved context and a custom prompt.


## Example:
Input: "What are the symptoms of diabetes?"
Output: (Assuming relevant info exists in the PDFs)

"Symptoms of diabetes include increased thirst, frequent urination, fatigue, and blurred vision.

[Source: data/document1.pdf, page 5]"

## Limitations
Answers are limited to the content in the provided PDFs.
Requires a stable internet connection for Hugging Face API calls.
Performance depends on the quality and quantity of the PDF data.
Contributing
Feel free to submit issues or pull requests to improve the chatbot. Suggestions for additional features (e.g., multi-language support, image processing) are welcome!

### License
This project is licensed under the MIT License. See the  file for details.

### Acknowledgments
Built with LangChain, Hugging Face, and Streamlit.
Inspired by the need for accessible medical information.